# ðŸ“„ **Drift-Testsystem â€“ Technische Dokumentation**

**Ort:** `docs/dev/drift-tests.md`
**Bereich:** Developer Documentation
**Zweck:** Technische Nutzung, Aufbau und Erweiterung der Skript-basierten Drift-Analyse

# 1. Ãœberblick

Dieses Dokument beschreibt die **technische Implementierung, Nutzung und Struktur** des skriptbasierten Drift-Testsystems.
Ziel ist es, **Promptsequenzen automatisiert an ein LLM (Gemini)** zu senden, die Ergebnisse reproduzierbar zu speichern und anschlieÃŸend automatisch auszuwerten.

Das System dient als Grundlage fÃ¼r:

* empirischen Drift-Nachweis
* Vergleichsexperimente
* QualitÃ¤tsanalyse im Kontext von ALOT2COME
* reproduzierbare LLM-Interaktionen

Die methodische Einordnung erfolgt separat unter
`docs/quality/drift-experiments.md`.

# 2. Verzeichnisstruktur

Die gesamte Drift-Test-Engine befindet sich unter:

```
src/drift/
â”œâ”€â”€ drift_experiment_gemini.py       # Experiment-Runner
â”œâ”€â”€ drift_analysis.py                # CLI Report Generator
â”œâ”€â”€ drift_analysis_core.py           # Analysemodul
â”œâ”€â”€ prompts/                         # Promptsets (JSON)
â”‚   â””â”€â”€ prompts.json
â””â”€â”€ results/                         # Ausgabedateien (.json/.md)
    â””â”€â”€ .gitignore
```

**Hinweise:**

* Der Ordner `results/` wird **nicht** versioniert (durch `.gitignore`).
* Alle Promptsets werden in `prompts/` versioniert.
* Die Analyse ist modular und unabhÃ¤ngig vom Experiment-Skript.

# 3. Promptsets (JSON)

Die Skripte erwarten eine JSON-Datei mit folgender Struktur:

```json
{
  "prompts": [
    "Wir definieren den Begriff Modul wie folgt...",
    "Welche Eigenschaften hat ein Modul?",
    "Bitte beschreibe ein Beispiel-Modul."
  ]
}
```

**Wichtige Merkmale:**

* Promptdateien sind **frei erweiterbar**, ohne CodeÃ¤nderungen.
* FÃ¼r jeden Testlauf kann eine eigene Datei verwendet werden.
* Die Dateien sind versionierbar und erlauben systematische Drift-Experimente.

# 4. Experiment-Skript: `drift_experiment_gemini.py`

Das Skript:

* lÃ¤dt die Promptdatei
* fÃ¼hrt jeden Prompt sequenziell an Gemini aus
* sammelt alle Antworten
* speichert sie als JSON
* nutzt das Gemini Free Tier
* enthÃ¤lt Fehlerbehandlung fÃ¼r fehlende Dateien und API-Keys

### **AusfÃ¼hrung**

Mit eigener Promptdatei:

```bash
python drift_experiment_gemini.py prompts/custom_prompts.json
```

Oder mit Standarddatei (`prompts.json`):

```bash
python drift_experiment_gemini.py
```

### **API-Key setzen**

Windows PowerShell:

```powershell
setx GEMINI_API_KEY "DEIN_API_KEY"
```

Dann neues PowerShell-Fenster Ã¶ffnen.

Test:

```powershell
echo $Env:GEMINI_API_KEY
```

# 5. Ergebnisdateien (JSON)

Das Experiment erzeugt eine Datei im Ordner `src/drift/`:

```
gemini_drift_experiment_2025-01-05_12-33-12.json
```

Diese Datei enthÃ¤lt:

* alle Prompts
* alle Antworten in Reihenfolge
* vollstÃ¤ndiges Drift-Testprotokoll

Sie dient als **Rohdatenbasis** fÃ¼r die Analyse.

# 6. Analyse-Engine: `drift_analysis_core.py`

Dieses Modul enthÃ¤lt alle wesentlichen Analysefunktionen:

* **Normalisierung** fÃ¼r Textvergleich
* **Ã„hnlichkeitsanalyse** (SequenceMatcher)
* **Wort-Differenzen** (added / removed words â†’ Begriffsdrift)
* **StrukturprÃ¼fungen** (Listen â†’ Strukturdrift)
* **automatische Textinterpretation**
* **Markdown-Report-Generator**

Das Modul wird sowohl vom

* CLI-Analyzer
* Experiment-Skript (optional)

verwendet.

# 7. CLI-Analyse: `drift_analysis.py`

Dieses Skript analysiert jede Ergebnis-JSON-Datei und erzeugt einen Markdown-Bericht.

### **AusfÃ¼hrung:**

```bash
python drift_analysis.py gemini_drift_experiment_2025-01-05_12-33-12.json
```

Ergebnis:

```
drift_report_2025-01-05_12-33-12.md
```

Der Bericht enthÃ¤lt:

* Vergleich Baseline â†” Kontrollpunkt
* Ã„hnlichkeitswert (0â€“1)
* neu hinzugekommene WÃ¶rter
* entfernte WÃ¶rter
* ListenverÃ¤nderungen
* automatische Interpretation
* Originalantworten

# 8. Optional: Auto-Analyse

Das Experiment-Skript unterstÃ¼tzt ein optionales `--analyze` Flag:

```bash
python drift_experiment_gemini.py prompts.json --analyze
```

Erzeugt:

* `gemini_drift_experiment_*.json`
* `drift_report_*.md`

Damit sind **Experiment und Analyse in einem Schritt** mÃ¶glich.

# 9. Troubleshooting

### **â€žGEMINI_API_KEY ist nicht gesetzt.â€œ**

â†’ API-Key als Umgebungsvariable setzen und Terminal neu starten.

### **â€žJSON-Datei nicht gefunden.â€œ**

â†’ Pfad prÃ¼fen oder Promptdatei in `/prompts/` ablegen.

### **â€žKein gÃ¼ltiges Prompts-Array.â€œ**

â†’ JSON prÃ¼fen (Liste unter `prompts`).

### **â€žFehler: Rate Limitâ€œ**

â†’ lÃ¤ngeres Delay einbauen (z. B. `time.sleep(1)`).

# 10. ErweiterungsmÃ¶glichkeiten

* Multi-LLM-UnterstÃ¼tzung (Claude, OpenAI, Mistral)
* Batch-Experimente
* GitHub Actions fÃ¼r nÃ¤chtliche Drift-Checks
* HTML-Reporting
* semantische Analyse per Embeddings
* Drift-Trendvisualisierungen

# 11. Bezug zur Methode ALOT2COME

Dieses Drift-Testsystem ist ein **technisches Werkzeug**, das folgende methodische Konzepte unterstÃ¼tzt:

* Drift-Management
* Persistenzmechanismen
* QualitÃ¤tskontrolle
* Reproduzierbarkeit
* evidenzbasierte Experimente

Die methodische Doku findest du unter:

```
docs/quality/drift-experiments.md
```

