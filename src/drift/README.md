# ðŸ“„ **README â€“ Drift-Testsystem**

Dieses Verzeichnis enthÃ¤lt alle Skripte und Komponenten zur automatisierten DurchfÃ¼hrung und Analyse von Drift-Experimenten im Rahmen der ALOT2COME-Methode. Das System ermÃ¶glicht reproduzierbare LLM-Experimente, die Entstehung von Drift messbar machen und deren Auswirkungen objektiv bewerten.

# 1. KomponentenÃ¼berblick

```
src/drift/
â”œâ”€â”€ drift_experiment_gemini.py       # Hauptskript: fÃ¼hrt Drift-Experimente durch
â”œâ”€â”€ drift_analysis_core.py           # Analysemodul: erkennt Driftarten & erzeugt Reports
â”œâ”€â”€ drift_analysis.py                # optionales CLI fÃ¼r nachtrÃ¤gliche Analysen
â”œâ”€â”€ drift_analysis_core_test.py      # Tests des Analysekerns
â”œâ”€â”€ prompts/                         # Promptsets fÃ¼r Experimente
â”‚   â””â”€â”€ prompts.json
â””â”€â”€ results/                         # Ergebnisse (.json + .md)
    â””â”€â”€ .gitignore
```

# 2. drift_experiment_gemini.py â€“ Experimentskript

Dieses Skript Ã¼bernimmt die vollstÃ¤ndige automatisierte DurchfÃ¼hrung eines Drift-Experiments.

### Funktionen

* lÃ¤dt eine Sequenz von Prompts aus einer JSON-Datei
* fÃ¼hrt jeden Prompt sequenziell an ein Gemini-Modell aus
* speichert Antworten als JSON-Artefakt
* unterstÃ¼tzt CLI-Parameter (`--prompts`, `--model`, `--analyze`)
* kann optional automatisch einen Drift-Report erzeugen

### Beispiele

Minimal:

```
python drift_experiment_gemini.py
```

Mit Promptdatei:

```
python drift_experiment_gemini.py --prompts prompts/moduldrift.json
```

Mit Analyse:

```
python drift_experiment_gemini.py --analyze
```

# 3. drift_analysis_core.py â€“ Analysemodul

Der **Analyse-Kern** ist unabhÃ¤ngig von allen anderen Skripten und bietet:

* Normalisierung von Texten
* Ã„hnlichkeitsanalyse (SequenceMatcher)
* Wortdifferenzen (Begriffsdrift)
* Strukturdrift (nummerierte Listen)
* automatische textliche Interpretation
* Erzeugung eines Markdown-Driftreports

Dieses Modul ist die Grundlage aller Driftanalysen und wird von mehreren Tools importiert.

# 4. drift_analysis.py â€“ CLI-Analyse (optional)

Dieses Skript ermÃ¶glicht die **nachtrÃ¤gliche Analyse** einer Ergebnisdatei:

```
python drift_analysis.py results/gemini_drift_experiment_<timestamp>.json
```

â†’ erzeugt einen Markdown-Report im Ordner `results/`.

# 5. Promptsets (prompts/)

Alle Promptsequenzen liegen in diesem Ordner.
Sie steuern das Drift-Experiment vollstÃ¤ndig, ohne dass das Skript selbst geÃ¤ndert werden muss.

Standarddatei:

```
prompts/prompts.json
```

Beispielinhalt:

```json
{
  "prompts": [
    "Definiere Modul.",
    "Bitte wiederhole die Definition.",
    "Welche Eigenschaften hat ein Modul?"
  ]
}
```

# 6. Ergebnisse (results/)

Alle Ergebnisse werden automatisch im Ordner `results/` gespeichert:

* `.json` â†’ Rohdaten, Antworten je Prompt
* `.md` â†’ Drift-Report (optional via `--analyze`)

Dieser Ordner wird nicht versioniert.

# 7. Voraussetzungen

* Python 3.10+
* Paket `google-generativeai`
* gesetzte Umgebungsvariable:

```
GEMINI_API_KEY=dein_api_key
```

# 8. Zweck des Drift-Testsystems

Das System dient dazu:

* Drift in LLM-Kollaborationen empirisch nachzuweisen
* Ergebnisse reproduzierbar zu machen
* QualitÃ¤tsmechanismen in ALOT2COME abzusichern
* das VerstÃ¤ndnis von Driftarten (Begriffsdrift, Strukturdrift etc.) zu vertiefen
* methodische Entscheidungen messbar zu begrÃ¼nden

Die methodische Dokumentation befindet sich unter:

```
docs/quality/drift-experiments.md
```

# 9. Weitere Schritte

* Erweiterung auf mehrere LLMs (Claude, OpenAI, Mistral)
* Batch-Experimente und Vergleichsreihen
* automatisierte Driftchecks per GitHub Actions
* Visualisierung von Drifttrends Ã¼ber mehrere Experimente
